{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tueminh.cao/miniconda3/envs/neurflow/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tueminh.cao/miniconda3/envs/neurflow/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "integrated gradients vs l2-norm weight\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils import split_model, batch_inference, get_conditional_modules, Model_wrapper, _wrapper, load_model_data, get_crop_data, accuracy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"googlenet\"\n",
    "data_dir = \"/mnt/disk1/user/Tue.CM210908/imagenet\"\n",
    "labels_list =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "model_name = model_name\n",
    "if model_name == \"resnet50\":\n",
    "    model = models.resnet50(pretrained=True).eval()\n",
    "    layers = [\"fc\", \"layer4.2\", \"layer4.1\", \"layer4.0\", \"layer3.5\", \"layer3.4\", \"layer3.3\", \"layer3.2\", \"layer3.1\", \"layer3.0\", \"layer2.3\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "elif model_name == \"googlenet\":\n",
    "    model = models.googlenet(pretrained=True).eval()\n",
    "    layers = [\"fc\", \"inception5b\", \"inception5a\", \"inception4e\", \"inception4d\", \"inception4c\", \"inception4b\", \"inception4a\", \"inception3b\", \"inception3a\", \"maxpool2\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "elif model_name == \"alexnet\":\n",
    "    model = models.alexnet(pretrained=True).eval()\n",
    "    layers = [\"classifier.6\", \"classifier.5\", \"classifier.2\", \"features.12\", \"features.9\", \"features.7\", \"features.5\", \"features.2\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "else:\n",
    "    raise ValueError(\"Model not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "def get_integrated_gradients(\n",
    "    syn_data: torch.Tensor,\n",
    "    fm_id: int,\n",
    "    netB: torch.nn.Module,\n",
    ") -> torch.Tensor:\n",
    "    integrated_gradients = IntegratedGradients(netB.to(device))\n",
    "    importance = []\n",
    "    for activation in syn_data:\n",
    "        activation = activation.unsqueeze(0).to(device)\n",
    "        activation.requires_grad = True\n",
    "        attributions_ig = integrated_gradients.attribute(\n",
    "            activation, baselines=activation * 0, target=fm_id\n",
    "        )\n",
    "        importance.append(\n",
    "            _wrapper(attributions_ig.detach().cpu())\n",
    "        )\n",
    "        \n",
    "    return torch.sum(torch.abs(torch.cat(importance)), dim=0)\n",
    "\n",
    "def masked_probing(data, indices, net, device = \"cuda\", batch_size = 256, reverse = True):\n",
    "    data = data.to(\"cpu\")\n",
    "    if reverse:\n",
    "        reverse_indices = [i for i in range(data.shape[1]) if i not in indices]\n",
    "        data[:, reverse_indices] = 0\n",
    "    else:\n",
    "        data[:, indices] = 0    \n",
    "    return batch_inference(net, data, batch_size=batch_size, device = device)\n",
    "\n",
    "def probing(data, net, device = \"cuda\", batch_size = 128):\n",
    "    return batch_inference(net, data, batch_size=batch_size, device = device)\n",
    "\n",
    "def top_img(probed, num_img = 5):\n",
    "    _, indices = torch.topk(probed, num_img)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "nums_top_neurons = [i for i in range(1, 17)]\n",
    "num_test_nodes = 1\n",
    "num_top_imgs = 50\n",
    "\n",
    "if model_name == \"resnet50\":\n",
    "    all_layers = [\"layer4.2\", \"layer4.1\", \"layer4.0\", \"layer3.5\",\n",
    "                \"layer3.4\", \"layer3.3\", \"layer3.2\", \"layer3.1\", \n",
    "                \"layer3.0\", \"layer2.3\"]\n",
    "elif model_name == \"googlenet\":\n",
    "    all_layers = [\"inception5b\", \"inception5a\", \"inception4e\", \"inception4d\",\n",
    "                \"inception4c\", \"inception4b\", \"inception4a\", \"inception3b\",\n",
    "                \"inception3a\", \"maxpool2\"]\n",
    "else:\n",
    "    raise ValueError(\"Model not supported\")\n",
    "\n",
    "diff_acc = []\n",
    "for layer_index in range(len(all_layers)-1):\n",
    "    print(\"Layer:\", all_layers[layer_index])\n",
    "    \n",
    "    start_layer = all_layers[layer_index+1]\n",
    "    end_layer = all_layers[layer_index]\n",
    "    \n",
    "    if model_name == \"resnet50\":\n",
    "        conv_end_layer = [end_layer.replace(\".\", \"_\"), \"conv1\"]\n",
    "    elif model_name == \"googlenet\":\n",
    "        conv_end_layer = [end_layer, \"branch1\", \"conv\"]\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported\")\n",
    "    \n",
    "    netA, temp = split_model(model, start_layer, True, conditional_modules=conditional_modules)\n",
    "    netB = Model_wrapper(\n",
    "        split_model(\n",
    "            temp, '.'.join(conv_end_layer), \n",
    "            True, \n",
    "            conditional_modules=conditional_modules\n",
    "        )[0]\n",
    "    )\n",
    "    \n",
    "    for label_id in tqdm(labels_list):\n",
    "        class_images, class_labels = load_model_data(data_dir, [label_id], model, device) \n",
    "        concept_data = get_crop_data(class_images)\n",
    "        \n",
    "        intermediate = batch_inference(netA, concept_data, device=device)\n",
    "        activation = batch_inference(netB, intermediate, device=device)\n",
    "        \n",
    "        num_node = activation.shape[1]\n",
    "        test_nodes = np.random.choice(num_node, num_test_nodes).tolist()  # choose random nodes\n",
    "        \n",
    "        for test_node in test_nodes:\n",
    "            top_imgs = torch.topk(activation[:, test_node], num_top_imgs)[1].detach().cpu().numpy()\n",
    "            importance = get_integrated_gradients(intermediate[torch.from_numpy(top_imgs)], test_node, netB).detach().cpu().numpy()\n",
    "            if (np.sum(importance) == 0):\n",
    "                print(\"No importance!\")\n",
    "                \n",
    "            weights = netB.model._modules['_'.join(conv_end_layer)].weight[test_node].clone() # type: ignore\n",
    "            l2_norm = torch.norm(weights.reshape(weights.shape[0], -1), dim=1)\n",
    "            for num_top_neurons in nums_top_neurons:\n",
    "                top_neurons = torch.topk(torch.from_numpy(importance), num_top_neurons)[1].detach().cpu().numpy()\n",
    "                top_filters = torch.topk(l2_norm, num_top_neurons)[1].detach().cpu().numpy()\n",
    "\n",
    "                mine = masked_probing(\n",
    "                    intermediate.clone(), top_neurons, netB, device = device, reverse=False, batch_size=64\n",
    "                )[:, test_node].detach().cpu()\n",
    "                top_img_mine = top_img(mine, num_img=num_top_imgs).numpy()\n",
    "                mine_acc = accuracy(top_imgs, top_img_mine)\n",
    "\n",
    "                them = masked_probing(\n",
    "                    intermediate.clone(), top_filters, netB, device = device, reverse=False, batch_size=64\n",
    "                )[:, test_node].detach().cpu()\n",
    "                top_img_them = top_img(them, num_img=num_top_imgs).numpy()\n",
    "                them_acc = accuracy(top_imgs, top_img_them)\n",
    "\n",
    "                diff_acc.append(mine_acc - them_acc)\n",
    "            \n",
    "print(\"Mean diff acc:\", np.mean(diff_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
