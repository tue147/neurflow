{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The independence on the value of k\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils import get_sub_model, split_model, batch_inference, get_conditional_modules, Model_wrapper, _wrapper, load_model_data, get_crop_data\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"googlenet\"\n",
    "data_dir = \"/mnt/disk1/user/Tue.CM210908/imagenet\"\n",
    "labels_list =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "model_name = model_name\n",
    "if model_name == \"resnet50\":\n",
    "    model = models.resnet50(pretrained=True).eval()\n",
    "    layers = [\"fc\", \"layer4.2\", \"layer4.1\", \"layer4.0\", \"layer3.5\", \"layer3.4\", \"layer3.3\", \"layer3.2\", \"layer3.1\", \"layer3.0\", \"layer2.3\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "elif model_name == \"googlenet\":\n",
    "    model = models.googlenet(pretrained=True).eval()\n",
    "    layers = [\"fc\", \"inception5b\", \"inception5a\", \"inception4e\", \"inception4d\", \"inception4c\", \"inception4b\", \"inception4a\", \"inception3b\", \"inception3a\", \"maxpool2\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "elif model_name == \"alexnet\":\n",
    "    model = models.alexnet(pretrained=True).eval()\n",
    "    layers = [\"classifier.6\", \"classifier.5\", \"classifier.2\", \"features.12\", \"features.9\", \"features.7\", \"features.5\", \"features.2\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "else:\n",
    "    raise ValueError(\"Model not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "def get_integrated_gradients(\n",
    "    syn_data: torch.Tensor,\n",
    "    fm_id: int,\n",
    "    netB: torch.nn.Module,\n",
    ") -> torch.Tensor:\n",
    "    integrated_gradients = IntegratedGradients(netB.to(device))\n",
    "    importance = []\n",
    "    for activation in syn_data:\n",
    "        activation = activation.unsqueeze(0).to(device)\n",
    "        activation.requires_grad = True\n",
    "        attributions_ig = integrated_gradients.attribute(\n",
    "            activation, baselines=activation * 0, target=fm_id\n",
    "        )\n",
    "        importance.append(\n",
    "            _wrapper(attributions_ig.detach().cpu())\n",
    "        )\n",
    "        \n",
    "    return torch.sum(torch.abs(torch.cat(importance)), dim=0)\n",
    "\n",
    "def masked_probing(data, indices, net, device = \"cuda\", batch_size = 256, reverse = True):\n",
    "    data = data.to(\"cpu\")\n",
    "    if reverse:\n",
    "        reverse_indices = [i for i in range(data.shape[1]) if i not in indices]\n",
    "        data[:, reverse_indices] = 0\n",
    "    else:\n",
    "        data[:, indices] = 0    \n",
    "    return batch_inference(net, data, batch_size=batch_size, device = device)\n",
    "\n",
    "def probing(data, net, device = \"cuda\", batch_size = 128):\n",
    "    return batch_inference(net, data, batch_size=batch_size, device = device)\n",
    "\n",
    "def top_img(probed, num_img = 5):\n",
    "    _, indices = torch.topk(probed, num_img)\n",
    "    return indices\n",
    "\n",
    "def overlap(tensor1, tensor2):\n",
    "    common_elements = np.intersect1d(tensor1, tensor2).shape[0]\n",
    "    return common_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "test_nodes = [i for i in range(10)]\n",
    "list_num_top_imgs = [10, 30, 40, 50, 60, 70, 90, 110, 130, 150, 170, 190]\n",
    "tau = 16\n",
    "\n",
    "all_list_overlap = {num_top_imgs : [] for num_top_imgs in list_num_top_imgs}\n",
    "\n",
    "for label_id in tqdm(labels_list):\n",
    "    print(f\"Label: {label_id}\")\n",
    "    class_images, class_labels = load_model_data(data_dir, [label_id], model, device) \n",
    "    concept_data = get_crop_data(class_images)\n",
    "    layer_index = random.choice(range(1, len(layers)+1)) # random layer\n",
    "\n",
    "    netA, _ = split_model(\n",
    "        model, layers[-layer_index], True, conditional_modules=conditional_modules\n",
    "    )\n",
    "    netB = Model_wrapper(\n",
    "        get_sub_model(\n",
    "            model, \n",
    "            layers[-layer_index], \n",
    "            layers[-layer_index-1], \n",
    "            True, \n",
    "            conditional_modules,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    intermediate = batch_inference(netA, concept_data, device=device)\n",
    "    activation = batch_inference(netB, intermediate, device=device)\n",
    "\n",
    "    num_node = intermediate.shape[1]\n",
    "    all_top_neurons = {node : [] for node in test_nodes}\n",
    "    baselines = {}\n",
    "    for test_node in tqdm(test_nodes):\n",
    "        for num_top_imgs in list_num_top_imgs:\n",
    "            top_imgs = torch.topk(activation[:, test_node], num_top_imgs)[1].detach().cpu().numpy()\n",
    "            \n",
    "            importance = get_integrated_gradients(\n",
    "                intermediate[torch.from_numpy(top_imgs)], test_node, netB\n",
    "            ).detach().cpu().numpy()\n",
    "            \n",
    "            top_neurons = torch.topk(torch.from_numpy(importance), tau)[1].detach().cpu().numpy()\n",
    "            all_top_neurons[test_node].append(top_neurons)\n",
    "            \n",
    "            if num_top_imgs == 50:\n",
    "                baselines[test_node] = top_neurons\n",
    "                \n",
    "    for i, num_top_imgs in enumerate(list_num_top_imgs):\n",
    "        list_overlap = []\n",
    "        for test_node in test_nodes:\n",
    "            list_overlap.append(overlap(all_top_neurons[test_node][i], baselines[test_node]))\n",
    "        all_list_overlap[num_top_imgs].append(list_overlap)\n",
    "\n",
    "for num_top_imgs in list_num_top_imgs:\n",
    "    print(f\"{num_top_imgs}: {np.mean(all_list_overlap[num_top_imgs])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
