{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Overlap of NeurFlow, NeuronMCT, NeuCEPT\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils import split_model, batch_inference, load_data, get_conditional_modules, Model_wrapper, _wrapper\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "from NeurFlow import Framework\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "directory = \"./fidelity_of_neuron/full_16/\"\n",
    "data_dir = \"/mnt/disk1/user/Tue.CM210908/imagenet\"\n",
    "model_name = \"resnet50\"\n",
    "label_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "tau = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torchvision import models\n",
    "if model_name == \"resnet50\":\n",
    "    model = models.resnet50(pretrained=True).eval()\n",
    "    all_layers = [\"layer4.2\", \"layer4.1\", \"layer4.0\", \"layer3.5\", \"layer3.4\",\n",
    "                  \"layer3.3\", \"layer3.2\", \"layer3.1\", \"layer3.0\", \"layer2.3\",\n",
    "                  \"layer2.2\", \"layer2.1\", \"layer2.0\", \"layer1.2\", \"layer1.1\", \"layer1.0\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "elif model_name == \"googlenet\":\n",
    "    model = models.googlenet(pretrained=True).eval()\n",
    "    all_layers = [\"inception5b\", \"inception5a\", \"inception4e\", \"inception4d\",\n",
    "                  \"inception4c\", \"inception4b\", \"inception4a\", \"inception3b\",\n",
    "                  \"inception3a\"]\n",
    "    conditional_modules = get_conditional_modules(model_name)\n",
    "else:\n",
    "    raise ValueError(\"Model not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from knockpy.knockoff_filter import KnockoffFilter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_integrated_gradients(\n",
    "    syn_data: torch.Tensor,\n",
    "    fm_id: int,\n",
    "    netB: torch.nn.Module,\n",
    "    batch_size: int = 8\n",
    ") -> torch.Tensor:\n",
    "    integrated_gradients = IntegratedGradients(netB.to(device))\n",
    "    importance = []\n",
    "    for i in range(0, len(syn_data), batch_size):\n",
    "        batch_data = syn_data[i:i + batch_size].to(device)\n",
    "        batch_data.requires_grad = True\n",
    "        attributions_ig = integrated_gradients.attribute(\n",
    "            batch_data, baselines=batch_data * 0, target=fm_id\n",
    "        )\n",
    "        importance.append(\n",
    "            _wrapper(attributions_ig.detach().cpu())\n",
    "        )\n",
    "        batch_data.cpu().detach()\n",
    "    return torch.sum(torch.abs(torch.cat(importance)), dim=0)\n",
    "\n",
    "def get_knockoff(\n",
    "    syn_data: torch.Tensor,\n",
    "    fm_id: int,\n",
    "    activation_target: torch.Tensor,\n",
    ") -> torch.Tensor: \n",
    "    attr = KnockoffFilter(ksampler='gaussian', fstat='lasso')\n",
    "    \n",
    "    def attribute(x, target):\n",
    "        x = _wrapper(x).detach().cpu().numpy()\n",
    "        attr.forward(\n",
    "            X=x, y=activation_target[:, target].detach().cpu().numpy(), fdr=1.0\n",
    "        )\n",
    "        return torch.from_numpy(attr.W)\n",
    "    \n",
    "    importance = []\n",
    "    attributions_ig = attribute(syn_data, fm_id)\n",
    "    importance.append(attributions_ig)\n",
    "    \n",
    "    return torch.abs(torch.cat(importance))\n",
    "\n",
    "def calculate_f1(set1, set2):\n",
    "    common_neurons = set1.intersection(set2)\n",
    "    tp = len(common_neurons) / len(set2) if len(set2) > 0 else 0\n",
    "    fp = len(set1 - set2) / len(set1) if len(set1) > 0 else 0\n",
    "    fn = len(set2 - set1) / len(set2) if len(set2) > 0 else 0\n",
    "    return 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {}\n",
    "\n",
    "for label_id in label_list:\n",
    "    path = directory+ f\"store_{model_name}_label{label_id}_tau{tau}.pth\"\n",
    "    store = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "    \n",
    "    FW = store[\"FW\"]\n",
    "    layers = store[\"layers\"]\n",
    "    del store\n",
    "    \n",
    "    all_images, all_labels = load_data(data_dir, [label_id]) \n",
    "    with torch.no_grad():\n",
    "        outputs = batch_inference(model, all_images, device=device)\n",
    "    \n",
    "    num_layers = len(FW.layers.keys()) - 1 # exclude the last layer\n",
    "    num_nodes_per_layer = [len(FW.layers[i].keys()) for i in range(1, num_layers+1)]\n",
    "    num_nodes = sum(num_nodes_per_layer)\n",
    "\n",
    "    all_neuronmct = {} # layer : neuronmct\n",
    "    all_knockoff = {} # layer : knockoff\n",
    "    for layer_index in tqdm(range(1, num_layers+1)):\n",
    "        netA, netB = split_model(model, layers[-layer_index-1], True, conditional_modules)\n",
    "        intermediate = batch_inference(netA, all_images, device=device)\n",
    "        # neuronmct (IG but to the output of the model)\n",
    "        importance = get_integrated_gradients(intermediate, label_id, netB)\n",
    "        # knockoff score\n",
    "        knockoff_score = get_knockoff(intermediate, label_id, outputs)\n",
    "        all_neuronmct[layer_index] = importance\n",
    "        all_knockoff[layer_index] = knockoff_score\n",
    "        \n",
    "    top_neurons_neuronmct = {}\n",
    "    top_neurons_neurflow = {}\n",
    "    top_neurons_knockoff = {}\n",
    "    for layer_index, scores in all_neuronmct.items():\n",
    "        # neuronmct (IG but to the output of the model)\n",
    "        top_neurons_neuronmct[layer_index] = set(torch.topk(scores, len(FW.layers[layer_index]))[1].numpy())\n",
    "        # neurflow\n",
    "        top_neurons_neurflow[layer_index] = set(FW.layers[layer_index].keys())\n",
    "        # knockoff\n",
    "        top_neurons_knockoff[layer_index] = set(torch.topk(all_knockoff[layer_index], len(FW.layers[layer_index]))[1].numpy())\n",
    "\n",
    "\n",
    "    for layer_index in range(1, num_layers + 1):\n",
    "        set1 = top_neurons_neuronmct[layer_index]\n",
    "        set2 = top_neurons_neurflow[layer_index]\n",
    "        set3 = top_neurons_knockoff[layer_index]\n",
    "\n",
    "        # Store all sets in a list\n",
    "        sets = [set1, set2, set3]\n",
    "        set_names = [\"NeuronMCT\", \"NeurFlow\", \"Knockoff\"]\n",
    "\n",
    "        # Calculate F1 scores for all pairs\n",
    "        for (i, j) in combinations(range(len(sets)), 2):\n",
    "            pair_name = f\"{set_names[i]}-{set_names[j]}\"\n",
    "            if pair_name not in f1_scores:\n",
    "                f1_scores[pair_name] = []\n",
    "            f1_scores[pair_name].append(calculate_f1(sets[i], sets[j]))\n",
    "\n",
    "# Print mean F1 scores for each pair\n",
    "for pair, scores in f1_scores.items():\n",
    "    print(f\"Mean F1 Score for {pair}: {np.mean(scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
